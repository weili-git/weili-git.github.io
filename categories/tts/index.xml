<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>TTS on Hugo tranquilpeak theme</title>
    <link>https://weili-git.github.io/categories/tts/</link>
    <description>Recent content in TTS on Hugo tranquilpeak theme</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 10 Dec 2023 15:14:00 +0900</lastBuildDate><atom:link href="https://weili-git.github.io/categories/tts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Analysis of Speech Emotion Intensity</title>
      <link>https://weili-git.github.io/2023/12/analysis-of-speech-emotion-intensity/</link>
      <pubDate>Sun, 10 Dec 2023 15:14:00 +0900</pubDate>
      
      <guid>https://weili-git.github.io/2023/12/analysis-of-speech-emotion-intensity/</guid>
      <description>1. Relative Attributes Extract emotion related features by OpenSMILE toolkit. (384-dim) Train Ranking function (Linear) based on the RA. Normalize the intensity values to the range 0 ~ 1. 2. Intensity Distribution 3. Intensity Embedding Map the real number to high dimensional embedding: (effective) $$Inty*W$$
Combine the neutral and emotional embeddings: (not so effective) $$Neu*(1-Inty)+Emo*Inty$$
Combine the neutral and emotional embeddings: (To be done) $$Neu.detach()(1-Inty)+EmoInty$$</description>
    </item>
    
    <item>
      <title>Intensity control of speech synthesis</title>
      <link>https://weili-git.github.io/2023/11/intensity-control-of-speech-synthesis/</link>
      <pubDate>Sat, 04 Nov 2023 21:18:00 +0900</pubDate>
      
      <guid>https://weili-git.github.io/2023/11/intensity-control-of-speech-synthesis/</guid>
      <description>1. Notes (1) We can&amp;rsquo;t regard different non-neutral speech pair as similar set, otherwise the emotional intensity labels attract each other.
(2) The intensity predictor should be fixed while training the text-to-speech model, otherwise the intensity cannot be controlled. (maybe because the label for each sample always fluctuates)</description>
    </item>
    
    <item>
      <title>TTS note 1</title>
      <link>https://weili-git.github.io/1/01/tts-note-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://weili-git.github.io/1/01/tts-note-1/</guid>
      <description>1. Continual Speaker Adaptation for Text-to-Speech Synthesis Catastrophic Forgetting (CA) happens when we try to fine-tune TTS model with new speakers. It will result in the decrease of performance for existing speakers.
To solve this problem, experience replay (ER) is utilized which will keep a buffer of samples from previous speakers and combine them with current task.
2. Bottleneck Layer Squeeze-and-Excitation Networks
&amp;ldquo;global pooling -&amp;gt; fc -&amp;gt; relu -&amp;gt; fc -&amp;gt; sigmoid&amp;rdquo;</description>
    </item>
    
  </channel>
</rss>
